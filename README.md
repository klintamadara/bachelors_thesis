# bachelors_thesis

This is the practical part of the Bachelor thesis “Image processing for evaluating ingredients list of food products” by Klinta Madara Greiliha. It aimed to create a solution that can extract an ingredient list from an image of a food label (in Latvian) and determine whether it is plant-based or if it contains animal-based ingredients. OCR engine used to extract text from images: open source Tesseract. Code is written in Python. 

Abbreviations used within the repository: "BGremove" - background removal, "noise" - noise removal, "B&W" - image converted to black and white (binary), "GS" - image converted to greyscale color scheme, "+" - a combination of the techniques, "PSM" - page segmentation mode, "AB" - animal-based.

The contents and the organization of this repository:
- file "list.txt" contains animal-based ingredients against which the solution compares each ingredient detected in the food product. The list includes the most common conjugations found in ingredient lists for most common animal based products (this is an important distinction neccessary from a solution that recognizes words in English). The list is not complete and could be improved, other conjugations could be added for safety - the more the list is developed, the more comprehensive it would be, and higher accuracy could be achieved, although improving the list has diminishing returs. The sources from which the infomration on animal-based ingredients were gathered are described in the thesis paper. 
- folder "images_raw" contains the sample of 200 images taken for the purposes of testing the solution. Each image depicts a food product label. 100 of them are plant-based or vegan (hence "v" in the title), and 100 are not plant-based (hence, "n" in the title).
- file "text_actual_animal_ingr_check.txt" contains information for testing and validating solution's accuracy. For each of the sample product label it contains the image name, total number of ingredients present in the product, the number of animal-based ingredients present in the product, as well as a list of all animal-based ingredients in the product if there are any.
- folder "texts_actual" contains the actual ingredient list for each of the sample products. Similarly to "text_actual_animal_ingr_check.txt", it is used for testing solution's accuracy. This information was manually collected from the sample images. In real life application, no such files would be available, and a consumer would have to trust the solution's result.
- folder "texts_raw" contain OCR output when the input is the original sample image. Tesseract offers different page segmentation modes (PSMs), and the folders denote the output for each tested PSM.
- folder "images_processed" contain the images after pre-processing techniques have been applied to them, and the corresponding OCR output is stored in the "texts_processed" folder. The folder "cropped_all" contains the output when a subset of 50 image samples were selected to test solution's accuracy when input is easily readable: sharp (non-blurry), homogenous, zoomed in to the ingredient list, has sufficient background/text contrast.
- Python codes can be found in folders "codes_extract_text_PSMs_and_IMAGES" and "codes_post-processing" which test out different PSMs and image processing techniques or several post-processing techniques, respectively. Codes that start with "extract" loop through all 200 sample images, open them, possibly modify them in the desired matter, store the resulted image and the OCR output when the engine is used on the resulted image. Codes that start with "lexical_check" loop through the 200 modified sample images' OCR output files and prepare Levenshtein distance, Jaccard similarity and Overlap coefficient measures, and store them in a txt file in the folder "results". These results were used to determine the best combination of pre-processing techniques: best PSM (which turned out to be mode 6), and best image processing (when image is converted to greyscale and has noise removes). Then, codes in "codes_post-processing" folder were used to determine the best post-processing technique. Post-processing included removing irrelevant information (everything in the detected text before "sastāvs"/ "sastāvdaļas"), exception handling (dismissing cases when the ingredient is a nut 'butter', a coconut 'milk' and similar occurences), correcting E-numbers wrongly classified as numbers (OCR recognizing the first character as 6 instead of E was a commonly observed error). Other post-processing techniques could be developed and added to the solution. There is a seperate file testing overall solution's accuracy (how many products are classified correctly, what is the recall, precision and F1 score for each sample in terms of animal-based VS plant-based ingredients) when no post-processing is applied, one file - when identical match is allowed during the execution of the post-processing techniques, one - when Levenshtein distance of lower or equal to 1 is allowed between the retrieved text and an actual animal-based ingredient, and one where Levenshtein distance of lower or equal to 25% of the ingredient length (in characters) is accepted. Each option looped through the 200 sample OCR outputs and applied the relevant post-processing techniques to the retrieved text, then identified the animal-based ingredients in the food product using the "list.txt" file, and finally compared the results with the information in the "text_actual_animal_ingr_check.txt" file to determine the correctly identified ingredients, the ones missed and the ones incorrectly flagged.
- folder "results" stores all of the results obtained by Python codes. It also includes (.jasp) files partly containing descriptive statistics of the results.

Best results (80% F1 score and 87.5% correct classification) were achieved when page segmentation mode 6 was used for the OCR engine to extract text from an image which was converted to greyscale and had noise removed. And then, the retrieved text was subject to identical match post-processing sequence to identify the animal-based ingredients in the food product.

P.S. Files were reorganized (split in more folders) after finsishing the project so that this repository would be easier to grasp and comprehend. Thus, if one wishes to clone it and test it out, changing "DIR" (directory) variables in the beginning of Python codes would be necessary for the codes to run (or the files would have to be moved to slightly different folder locations).
